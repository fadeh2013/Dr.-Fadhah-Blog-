{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "In addition to Dr. Fadhah's publications, this website provides several short toturials to R and Statistics. ",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2023-11-04T15:43:13+03:00"
    },
    {
      "path": "hypothesisSmean.html",
      "title": "Hypothesis for a single mean",
      "description": "Introduction to hypothesis test for a single mean.\n",
      "author": [
        {
          "name": "Dr. Fadhah Alanazi",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\nHypothesis test\nBasically, a hypothesis test is a statistical method to test a claim, believes or a status quo. In this page we are interest in the\nhypothesis test for a single mean, such that we are interested in one sample.\nFormulate the hypothesis test\nIn hypothesis test, a researcher needs to formulating two competing hypotheses, the null hypothesis (\\(H_0\\)) and the alternative hypothesis\n(\\(H_a\\)). After that, he/she needs to use a statistical evidence to evaluate which hypothesis is more likely.\nPopulation statndard deviation is known\nIf the population standard deviation is known (\\(\\sigma\\)), or we have a large sample size, then we can use the \\(Z\\)-Statistics.\n\\[Z _\\textit{test} = \\frac{(\\bar{x} - μ)} {(σ / √n)}\\]\nWhere:\n\\(z\\) is the z-statistic\n\\(\\bar{x}\\) is the sample mean\n\\(μ\\) is the population mean\n\\(σ\\) is the population standard deviation\n\\(n\\) is the sample size\nExample of using Z-statistics\nFirst of all, suppose we need to test the following hypothesis test:\n\\[H_0: \\mu = 200\\]\n\\[H_a: \\mu \\neq 200\\]\nWith \\[n = 50, \\ \\bar{x} = 197, \\  \\mu = 200, \\ \\sigma = 9, \\ \\alpha = 0.05\\]\nSolution:\nIs the population standard deviation known?\nYes, the population standard deviation is known and given as \\(\\sigma = 9\\).\nCan we use the Z-statistics to test the hypothesis, and why?\nYes. Because if the population standard deviation is known we can use \\(Z\\)-Statistics, also the sample size is large (\\(n \\geq 30\\)).\nHow many rejection area do we have in this case, and why?\nIn this case, there are two rejection areas. Because the alternative hypothesis has unequal sign (“\\(\\neq\\)”). That is,\nthe rejection region are determined based on the sign of the alternative hypothesis.\nOk. If we have two rejection regions, what we should do with the significant level?\nIf we have two rejections areas, then we must divide the significant level (\\(\\alpha\\)) by \\(2\\). That is: \\[\\alpha /2 = 0.05/2 = 0.025\\]\nGreat! What is next?\nNow we need to specify the decision rule, as follows:\nDecision Rule:\nDecision rule is just a decision that we made regarding rejecting or fail to reject the null hypothesis (\\(H_0\\)).\nFirst we need to formulate the decision rule. That is, when we reject \\(H_0\\) and when we fail to reject \\(H_0\\).\n_ To formulate the decision rule, a good idea is to draw a graph and to specify the rejection region, as follows:\nNormal and Rejection areasFrom the above graph, we can see that we have two rejection regions. The cut-off (border) of the rejection region start at\n\\(Z_{\\alpha/2}\\) \\(= 1.96\\) at the right side, and at \\(- Z_{\\alpha/2}\\) \\(= - 1.96\\) at the left side. That is, the rejection regions are the red areas.\nGreate! But what does this mean?\n(Simply) The rejection region is the area that if the \\(Z\\)-statistics or \\(Z\\)-test fall in, then we need to reject the null hypothesis.\nGreat! What next?\nNow, we need to specify the decision rule. When we reject the \\(H_0\\) and when fail to reject \\(H_0\\) based on the rejection areas as follows:\n\\[ If \\ Z_{test} > Z_{\\alpha/2} = 1.96 \\rightarrow \\  Reject \\ H_0\\]\nor\n\\[ If \\ - Z_{test} < - Z_{\\alpha/2} = - 1.96 \\rightarrow \\  Reject \\ H_0\\]\nOtherwise do not reject \\(H_0\\).\nExplaining the Decision rule\n\\[ If \\ Z_{test} > Z_{\\alpha/2} = 1.96 \\rightarrow \\  Reject \\ H_0\\]\nThis part of the decision rule said that: If the value of the \\(Z_{test}\\) larger than the right border of the rejection area,\nthen we need to reject the \\(H_0\\).\nOk. But why? That is because it falls inside the rejection area!\nOk. How about the left hand-side? The same situation. That is:\n\\[ If \\ - Z_{test} < - Z_{\\alpha/2} = - 1.96 \\rightarrow \\  Reject \\ H_0\\]\nThis part of the decision rule said that: If the value of the \\(- Z_{test}\\) smaller than the left border of the rejection area,\nthen we need to reject the \\(H_0\\). Because it falls inside the rejection area.\nGreat! So we should compare the Z-test with the critical value.\nThe graph shows the value of the \\(- Z_{test} = -2.36\\). From the graph, the \\(- Z_{test} = -2.36\\) falls inside the left\nrejection area.\nOk. What does this means?\nAs explained above, it means that the \\(- Z_{test} = -2.36\\) is smaller than the \\(- Z_{\\alpha/2} = -1.96\\). In other words, the \\(- Z_{test}\\) is inside the\nrejection region. Hence, based on the decision rule, we need to reject \\(H_0\\).\nNormalConclusion\nBecause the \\(Z_{test}\\) \\(= -2.36\\) is smaller than the \\(Z_{\\alpha/2}\\) = \\(-1.96\\), and hence falls in the rejection region, we reject \\(H_0\\), and conclude that, the population mean is not equal to \\(200\\). Because we reject \\(H_0\\).\n\n\n\n",
      "last_modified": "2023-11-04T15:43:14+03:00"
    },
    {
      "path": "index.html",
      "title": "Dr. Fadhah Alanazi",
      "author": [],
      "contents": "\n\n          \n          \n          Dr. Fadhah Alanazi\n          \n          \n          Publications\n          \n          \n          Lessons\n           \n          ▾\n          \n          \n          Sample and Population\n          Central and Variation\n          hypothesis for one mean\n          Introduction to Rstudio\n          Normal distribution\n          \n          \n          About\n          ☰\n          \n          \n      \n        \n          \n            \n              \n            \n              Dr. Fadhah Alanazi\n            \n            \n              \n                \n                    \n                      \n                         GitHub\n                      \n                    \n                  \n                                    \n                    \n                      \n                         LinkedIn\n                      \n                    \n                  \n                                  \n            \n          \n        \n        \n        \n          \n            \n            Bio\n            Dr. Fadhah Alanazi has a master’s degree from the\n            Australian National University, Canberra, and a Ph.D from\n            Queensland University of Technology. She is an expert in R\n            and Rstudio.\n            \n            \n            Education\n            Queensland University of Technology |\n            Brisbane, Australia\n            Ph.D. in Statistics | July 2015 - August 2019\n            Australian National University |\n            Canberra, Australia\n            Master in Mathematical Science | February 2011 - July\n            2013\n            \n            \n            Experience\n            Prince Sultan University | Statistics\n            instructor | January 2020 - Present\n            Northern Border University | Statistics\n            instructor | June 2014 - June 2015\n            \n          \n        \n      \n    \n\n    \n      \n        \n          \n            \n              \n            \n              Dr. Fadhah Alanazi\n            \n            \n              \n                \n                                    \n                    \n                       GitHub\n                    \n                  \n                                    \n                    \n                       LinkedIn\n                    \n                  \n                                  \n              \n            \n            \n              \n              Bio\n              Dr. Fadhah Alanazi has a master’s degree from the\n              Australian National University, Canberra, and a Ph.D from\n              Queensland University of Technology. She is an expert in R\n              and Rstudio.\n              \n              \n              Education\n              Queensland University of Technology |\n              Brisbane, Australia\n              Ph.D. in Statistics | July 2015 - August 2019\n              Australian National University |\n              Canberra, Australia\n              Master in Mathematical Science | February 2011 - July\n              2013\n              \n              \n              Experience\n              Prince Sultan University | Statistics\n              instructor | January 2020 - Present\n              Northern Border University |\n              Statistics instructor | June 2014 - June 2015\n              \n            \n        \n      \n    \n\n    \n    \n    ",
      "last_modified": "2023-11-04T15:44:10+03:00"
    },
    {
      "path": "Normal_Distribution.html",
      "title": "Standard normal distribution",
      "description": "Brief introduction to normal and standard normal distribution.\n",
      "author": [
        {
          "name": "Dr. Fadhah Alanazi",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\nThe normal distribution, also known as the Gaussian distribution or bell curve, is a fundamental concept in statistics and probability theory. It describes a continuous probability distribution for a random variable, where the data tends to cluster around the mean value with decreasing frequency as it moves away from the mean.\nThe normal distribution is defined by two parameters: the mean (\\(\\mu\\)) and the standard deviation (\\(\\sigma\\)).\nThe mean represents the center or average value of the distribution, while the standard deviation measures the spread or variability of the data.\nThe shape of the normal distribution is symmetric and bell-shaped, with the highest point at the mean. The curve is characterized by the empirical rule, also known as the \\(68-95-99.7\\) rule, which states that:\nApproximately \\(68\\%\\) of the data falls within one standard deviation of the mean.\nApproximately \\(95\\%\\) of the data falls within two standard deviations of the mean.\nApproximately \\(99.7\\%\\) of the data falls within three standard deviations of the mean.\nThe normal distribution has several important properties that make it widely used in various fields. These include:\nCentral Limit Theorem: The sum or average of a large number of independent and identically distributed random variables tends to follow a normal distribution, regardless of the shape of the original distribution.\nZ-Score: The z-score, also known as the standard score, is a measure of how many standard deviations an observation or data point is away from the mean. It allows for standardized comparisons between different values and is commonly used in hypothesis testing and statistical analysis. Any normal distribution can be converted to the standard normal distribution using the z-score formula:\n\\[\\begin{equation}\nz = \\frac{x - \\mu}{\\sigma}\n\\end{equation}\\]\nProbability Density Function (PDF): The normal distribution is described by a probability density function, which gives the probability of observing a particular value or range of values. The PDF is defined by the mean and standard deviation parameters.\nWhen working with the z-table we have three different situations as follows:\nWhen the \\(x\\), \\(\\mu\\) and the \\(\\sigma\\) values are given in the question. In this case, we cannot use the z-table directly as\nit is designed for the standard normal distribution. Hence, we first need to transform the normal distribution with the given\nvalues into standard one using the z-score formula as shown above. The following is an example of this case.\nFirst wayThe second way is when we are given the z-value, so here there is no need to use the z-score step. Hence, we can\ndirectly use the z-table. See the following example.\nSecond wayThe third way is when we are given the probability, and we need to find the z or x values. This case is called the inverse\nnormal distribution. See the following example.\nThird way\n\n\n",
      "last_modified": "2023-11-04T15:44:11+03:00"
    },
    {
      "path": "Publications.html",
      "title": "Puplications",
      "description": "The publications of Dr. Fadhah Amer Alanazi\n",
      "author": [
        {
          "name": "Dr. Fadhah Amer Alanazi",
          "url": "https://scholar.google.com/citations?user=_QLWj-0AAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nMixture Vine Copula\nCOVID-19 and Copula\nTruncation R-vine Copula\n\nMixture Vine Copula\nA mixture of regular vines for multiple dependencies:\nMixture R-Vine Copula.\nCOVID-19 and Copula\nThe spread of COVID-19 at Hot-Temperature Places With Different Curfew Situations Using Copula Models:\nCOVID-19 and Copula.\nTruncation R-vine Copula\nSequential truncation of r-vine copula mixture model for high-dimensional datasets:\nSquential Truncation.\nTruncating regular vine copula based on mutual information: An efficient parsimonious model for high-dimensional data:\nMI and turncation R-vine copoula.\nNovel pruning and truncating of the mixture of vine copula clustering models:\nNovel mixture Truncaion.\n\n\n\n",
      "last_modified": "2023-11-04T15:44:12+03:00"
    },
    {
      "path": "Stat1.html",
      "title": "Sample and Population",
      "description": "A simple introduction to sample and population. \n",
      "author": [
        {
          "name": "Dr. Fadhah Alanai",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\nPopulation\nPopulation refers to the entire set of items or objectives that are of interest to a specific study, such as a group of people,\nanimals, and objectives.\nStudying the population is a complex task, often challenging and impractical. One reason for that is the size of the\npopulation. In many real-life cases, the population size is vast, making it time-consuming and challenging to access and collect the required data\nfrom each member of the population.\nSample\nSample is a part (or a subset) of the population.\nSample is collected from the population under the study to make inferences about the entire population.\nDue to sample variability, there will always be a potential for sample error.\nSample error refers to the difference between the population and the sample taken from it.\nSample techniques\nSampling techniques can be divided into statistical and non-statistical methods.\nNon-statistical Sampling method\nConvenience sampling:\nIt is a non-probability sampling technique.\nThe researchers selected the individuals based on their availability and willingness to participate.\nIt is easy and cost-effective in comparison to other sampling techniques.\nDue to the lack of random selection, it may lead to selection bias.\nJudgment sampling:\nIt is a non-probability sampling technique.\nIt is based on the researchers’ judgment and experiences.\nIt is cost-effective as the researchers focus on specific groups in this sampling method.\nThis method may lead to potential bias as it is based on the researcher’s judgment, and hence, the selected individuals may influenced by the researcher’s bias or pre-conceptions.\nStatistical Sampling method\nSimple random sample:\nIn simple random sampling, each person/item/subject has an equally likely chance to be selected.\nComing Soon!\n\n\n\n",
      "last_modified": "2023-11-04T15:44:13+03:00"
    },
    {
      "path": "Stat2.html",
      "title": "Central and Variation",
      "description": "Here we will learn the central and variation of the data.\n",
      "author": [
        {
          "name": "Dr. Fadhah Alanai",
          "url": {}
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\nComing Soon!\n\n\n\n",
      "last_modified": "2023-11-04T15:44:13+03:00"
    }
  ],
  "collections": []
}
